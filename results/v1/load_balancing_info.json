{
  "id": "6214f6632f7004d0",
  "code": "/// Load Balancing (MoE Expert-to-GPU Assignment) - Lock-Free Implementation\n/// Uses atomic operations and crossbeam-epoch for wait-free load balancing.\n\nuse crossbeam_epoch::{self as epoch, Atomic, Owned, Shared};\nuse std::sync::atomic::{AtomicU64, AtomicUsize, Ordering};\nuse std::sync::Arc;\n\n/// An expert with compute requirements.\n#[derive(Debug, Clone)]\npub struct Expert {\n    pub id: u64,\n    pub compute_cost: f64,\n    pub memory_bytes: u64,\n    pub activation_frequency: f64,\n}\n\n/// Expert-to-GPU assignment result.\n#[derive(Debug, Clone)]\npub struct Assignment {\n    pub expert_id: u64,\n    pub gpu_id: u64,\n}\n\n/// Result of load balancing.\n#[derive(Debug, Clone)]\npub struct BalancingResult {\n    pub assignments: Vec<Assignment>,\n    pub max_gpu_load: f64,\n    pub load_imbalance: f64,\n    pub memory_violations: u64,\n}\n\n#[derive(Debug)]\nstruct GpuState {\n    load: AtomicU64, // Fixed-point representation (multiply by 1000)\n    memory: AtomicU64,\n}\n\nstruct LoadBalancer {\n    gpus: Vec<Arc<GpuState>>,\n    num_gpus: u64,\n    gpu_memory_bytes: u64,\n    assignment_counter: AtomicUsize,\n}\n\nimpl LoadBalancer {\n    fn new(num_gpus: u64, gpu_memory_bytes: u64) -> Self {\n        let mut gpus = Vec::with_capacity(num_gpus as usize);\n        for _ in 0..num_gpus {\n            gpus.push(Arc::new(GpuState {\n                load: AtomicU64::new(0),\n                memory: AtomicU64::new(0),\n            }));\n        }\n        \n        Self {\n            gpus,\n            num_gpus,\n            gpu_memory_bytes,\n            assignment_counter: AtomicUsize::new(0),\n        }\n    }\n\n    fn find_best_gpu(&self, expert: &Expert) -> u64 {\n        let mut best_gpu = 0;\n        let mut best_score = f64::INFINITY;\n        \n        let expert_load_fp = ((expert.compute_cost * expert.activation_frequency) * 1000.0) as u64;\n        \n        for (gpu_id, gpu) in self.gpus.iter().enumerate() {\n            let current_load = gpu.load.load(Ordering::Relaxed);\n            let current_memory = gpu.memory.load(Ordering::Relaxed);\n            \n            // Check memory constraint\n            if current_memory + expert.memory_bytes > self.gpu_memory_bytes {\n                continue;\n            }\n            \n            // Calculate load after assignment\n            let new_load = current_load + expert_load_fp;\n            let load_score = new_load as f64 / 1000.0;\n            \n            // Add memory pressure penalty\n            let memory_ratio = (current_memory + expert.memory_bytes) as f64 / self.gpu_memory_bytes as f64;\n            let total_score = load_score * (1.0 + memory_ratio * 0.5);\n            \n            if total_score < best_score {\n                best_score = total_score;\n                best_gpu = gpu_id;\n            }\n        }\n        \n        best_gpu as u64\n    }\n\n    fn assign_expert(&self, expert: &Expert) -> Assignment {\n        let expert_load_fp = ((expert.compute_cost * expert.activation_frequency) * 1000.0) as u64;\n        \n        loop {\n            let gpu_id = self.find_best_gpu(expert);\n            let gpu = &self.gpus[gpu_id as usize];\n            \n            // Try to atomically update both load and memory\n            let old_load = gpu.load.load(Ordering::Relaxed);\n            let old_memory = gpu.memory.load(Ordering::Relaxed);\n            \n            // Check memory constraint again\n            if old_memory + expert.memory_bytes > self.gpu_memory_bytes {\n                // Fallback to round-robin if no GPU has enough memory\n                let counter = self.assignment_counter.fetch_add(1, Ordering::Relaxed);\n                let fallback_gpu_id = (counter as u64) % self.num_gpus;\n                let fallback_gpu = &self.gpus[fallback_gpu_id as usize];\n                \n                fallback_gpu.load.fetch_add(expert_load_fp, Ordering::Relaxed);\n                fallback_gpu.memory.fetch_add(expert.memory_bytes, Ordering::Relaxed);\n                \n                return Assignment {\n                    expert_id: expert.id,\n                    gpu_id: fallback_gpu_id,\n                };\n            }\n            \n            // Try to update load atomically\n            match gpu.load.compare_exchange_weak(\n                old_load,\n                old_load + expert_load_fp,\n                Ordering::Relaxed,\n                Ordering::Relaxed,\n            ) {\n                Ok(_) => {\n                    // Successfully updated load, now update memory\n                    gpu.memory.fetch_add(expert.memory_bytes, Ordering::Relaxed);\n                    \n                    return Assignment {\n                        expert_id: expert.id,\n                        gpu_id,\n                    };\n                }\n                Err(_) => {\n                    // Retry with updated state\n                    continue;\n                }\n            }\n        }\n    }\n\n    fn get_final_state(&self) -> (Vec<f64>, Vec<u64>) {\n        let loads: Vec<f64> = self.gpus.iter()\n            .map(|gpu| gpu.load.load(Ordering::Relaxed) as f64 / 1000.0)\n            .collect();\n        \n        let memory: Vec<u64> = self.gpus.iter()\n            .map(|gpu| gpu.memory.load(Ordering::Relaxed))\n            .collect();\n            \n        (loads, memory)\n    }\n}\n\n/// Assign experts to `num_gpus` GPUs, each with given compute and memory capacity.\n///\n/// Returns assignments minimizing max GPU load imbalance using lock-free algorithms.\n/// `gpu_memory_bytes` is the memory capacity per GPU.\npub fn balance_load(\n    experts: &[Expert],\n    num_gpus: u64,\n    gpu_memory_bytes: u64,\n) -> BalancingResult {\n    debug_assert!(num_gpus > 0, \"Must have at least one GPU\");\n    debug_assert!(!experts.is_empty(), \"Must have at least one expert\");\n\n    let balancer = LoadBalancer::new(num_gpus, gpu_memory_bytes);\n    let mut assignments = Vec::with_capacity(experts.len());\n\n    // Sort experts by compute cost (descending) for better load balancing\n    let mut sorted_experts: Vec<_> = experts.iter().collect();\n    sorted_experts.sort_by(|a, b| {\n        let load_a = a.compute_cost * a.activation_frequency;\n        let load_b = b.compute_cost * b.activation_frequency;\n        load_b.partial_cmp(&load_a).unwrap_or(std::cmp::Ordering::Equal)\n    });\n\n    // Assign experts using lock-free operations\n    for expert in sorted_experts {\n        assignments.push(balancer.assign_expert(expert));\n    }\n\n    let (gpu_loads, gpu_memory) = balancer.get_final_state();\n\n    let max_gpu_load = gpu_loads.iter().copied().fold(0.0_f64, f64::max);\n    let avg_load: f64 = gpu_loads.iter().sum::<f64>() / num_gpus as f64;\n    let load_imbalance = if avg_load > 0.0 {\n        max_gpu_load / avg_load\n    } else {\n        1.0\n    };\n\n    let memory_violations = gpu_memory\n        .iter()\n        .filter(|&&mem| mem > gpu_memory_bytes)\n        .count() as u64;\n\n    BalancingResult {\n        assignments,\n        max_gpu_load,\n        load_imbalance,\n        memory_violations,\n    }\n}",
  "score": 270.0,
  "correct": true,
  "generation": 3,
  "parent_id": "d4148c4b8dbfe507",
  "island": 1,
  "level_reached": 1,
  "progress": "LockFree",
  "feedback": "## Cascade Results:\n- rustc: PASS (30.9s)\n- miri: PASS (58.5s)\n",
  "model": "sonnet"
}