{
  "id": "065eb3d75b696aa3",
  "code": "use crossbeam_epoch::{self as epoch, Atomic, Guard, Owned, Shared};\nuse std::cmp::Ordering;\nuse std::sync::atomic::{AtomicUsize, Ordering as AtomicOrdering};\n\nconst B: usize = 6;\n\n#[derive(Debug)]\nstruct Node {\n    keys: Vec<u64>,\n    vals: Vec<u64>,\n    children: Vec<Atomic<Node>>,\n    next: Atomic<Node>,\n    is_leaf: bool,\n}\n\nimpl Node {\n    fn new_leaf() -> Self {\n        Node {\n            keys: Vec::with_capacity(2 * B - 1),\n            vals: Vec::with_capacity(2 * B - 1),\n            children: Vec::new(),\n            next: Atomic::null(),\n            is_leaf: true,\n        }\n    }\n\n    fn new_internal() -> Self {\n        Node {\n            keys: Vec::with_capacity(2 * B - 1),\n            vals: Vec::new(),\n            children: Vec::with_capacity(2 * B),\n            next: Atomic::null(),\n            is_leaf: false,\n        }\n    }\n}\n\npub struct ConcurrentBTree {\n    root: Atomic<Node>,\n    len: AtomicUsize,\n}\n\nimpl ConcurrentBTree {\n    pub fn new() -> Self {\n        ConcurrentBTree {\n            root: Atomic::new(Node::new_leaf()),\n            len: AtomicUsize::new(0),\n        }\n    }\n\n    pub fn insert(&self, key: u64, value: u64) {\n        let guard = &epoch::pin();\n        loop {\n            let root_ptr = self.root.load(AtomicOrdering::Acquire, guard);\n            if root_ptr.is_null() {\n                let new_root = Owned::new(Node::new_leaf());\n                match self.root.compare_exchange(\n                    Shared::null(),\n                    new_root,\n                    AtomicOrdering::Release,\n                    AtomicOrdering::Acquire,\n                    guard,\n                ) {\n                    Ok(_) => continue,\n                    Err(_) => continue,\n                }\n            }\n\n            let root_ref = unsafe { root_ptr.deref() };\n            \n            if root_ref.is_leaf {\n                if self.insert_into_leaf(key, value, root_ptr, guard) {\n                    self.len.fetch_add(1, AtomicOrdering::Relaxed);\n                    return;\n                }\n            } else {\n                if self.insert_into_internal(key, value, root_ptr, guard) {\n                    self.len.fetch_add(1, AtomicOrdering::Relaxed);\n                    return;\n                }\n            }\n        }\n    }\n\n    fn insert_into_leaf(&self, key: u64, value: u64, node_ptr: Shared<Node>, guard: &Guard) -> bool {\n        let node = unsafe { node_ptr.deref() };\n        \n        let mut new_node = Node::new_leaf();\n        new_node.keys = node.keys.clone();\n        new_node.vals = node.vals.clone();\n        \n        match new_node.keys.binary_search(&key) {\n            Ok(pos) => {\n                new_node.vals[pos] = value;\n            }\n            Err(pos) => {\n                new_node.keys.insert(pos, key);\n                new_node.vals.insert(pos, value);\n            }\n        }\n\n        if new_node.keys.len() >= 2 * B {\n            return false;\n        }\n\n        let new_ptr = Owned::new(new_node).into_shared(guard);\n        \n        if node_ptr == self.root.load(AtomicOrdering::Acquire, guard) {\n            match self.root.compare_exchange(\n                node_ptr,\n                new_ptr,\n                AtomicOrdering::Release,\n                AtomicOrdering::Acquire,\n                guard,\n            ) {\n                Ok(_) => {\n                    unsafe { guard.defer_destroy(node_ptr) };\n                    true\n                }\n                Err(_) => {\n                    unsafe { new_ptr.into_owned() };\n                    false\n                }\n            }\n        } else {\n            false\n        }\n    }\n\n    fn insert_into_internal(&self, key: u64, value: u64, node_ptr: Shared<Node>, guard: &Guard) -> bool {\n        let node = unsafe { node_ptr.deref() };\n        \n        let pos = node.keys.binary_search(&key).unwrap_or_else(|p| p);\n        let child_idx = if pos < node.keys.len() && key >= node.keys[pos] {\n            pos + 1\n        } else {\n            pos\n        };\n\n        if child_idx < node.children.len() {\n            let child_ptr = node.children[child_idx].load(AtomicOrdering::Acquire, guard);\n            if !child_ptr.is_null() {\n                let child = unsafe { child_ptr.deref() };\n                if child.is_leaf {\n                    return self.insert_into_leaf(key, value, child_ptr, guard);\n                } else {\n                    return self.insert_into_internal(key, value, child_ptr, guard);\n                }\n            }\n        }\n        \n        false\n    }\n\n    pub fn get(&self, key: &u64) -> Option<u64> {\n        let guard = &epoch::pin();\n        let mut current = self.root.load(AtomicOrdering::Acquire, guard);\n        \n        while !current.is_null() {\n            let node = unsafe { current.deref() };\n            \n            if node.is_leaf {\n                match node.keys.binary_search(key) {\n                    Ok(pos) => return Some(node.vals[pos]),\n                    Err(_) => return None,\n                }\n            } else {\n                let pos = node.keys.binary_search(key).unwrap_or_else(|p| p);\n                let child_idx = if pos < node.keys.len() && *key >= node.keys[pos] {\n                    pos + 1\n                } else {\n                    pos\n                };\n                \n                if child_idx < node.children.len() {\n                    current = node.children[child_idx].load(AtomicOrdering::Acquire, guard);\n                } else {\n                    return None;\n                }\n            }\n        }\n        \n        None\n    }\n\n    pub fn remove(&self, key: &u64) -> bool {\n        let guard = &epoch::pin();\n        let root_ptr = self.root.load(AtomicOrdering::Acquire, guard);\n        \n        if root_ptr.is_null() {\n            return false;\n        }\n        \n        let root = unsafe { root_ptr.deref() };\n        \n        if root.is_leaf {\n            match root.keys.binary_search(key) {\n                Ok(pos) => {\n                    let mut new_node = Node::new_leaf();\n                    new_node.keys = root.keys.clone();\n                    new_node.vals = root.vals.clone();\n                    new_node.keys.remove(pos);\n                    new_node.vals.remove(pos);\n                    \n                    let new_ptr = Owned::new(new_node).into_shared(guard);\n                    \n                    match self.root.compare_exchange(\n                        root_ptr,\n                        new_ptr,\n                        AtomicOrdering::Release,\n                        AtomicOrdering::Acquire,\n                        guard,\n                    ) {\n                        Ok(_) => {\n                            unsafe { guard.defer_destroy(root_ptr) };\n                            self.len.fetch_sub(1, AtomicOrdering::Relaxed);\n                            true\n                        }\n                        Err(_) => {\n                            unsafe { new_ptr.into_owned() };\n                            false\n                        }\n                    }\n                }\n                Err(_) => false,\n            }\n        } else {\n            false\n        }\n    }\n\n    pub fn range(&self, start: u64, end: u64) -> Vec<(u64, u64)> {\n        let guard = &epoch::pin();\n        let mut result = Vec::new();\n        \n        let root_ptr = self.root.load(AtomicOrdering::Acquire, guard);\n        if root_ptr.is_null() {\n            return result;\n        }\n        \n        self.collect_range(root_ptr, start, end, &mut result, guard);\n        result\n    }\n\n    fn collect_range(&self, node_ptr: Shared<Node>, start: u64, end: u64, result: &mut Vec<(u64, u64)>, guard: &Guard) {\n        let node = unsafe { node_ptr.deref() };\n        \n        if node.is_leaf {\n            for (i, &k) in node.keys.iter().enumerate() {\n                if k >= start && k < end {\n                    result.push((k, node.vals[i]));\n                }\n            }\n        } else {\n            for (i, &k) in node.keys.iter().enumerate() {\n                if k >= end {\n                    break;\n                }\n                \n                if i < node.children.len() {\n                    let child = node.children[i].load(AtomicOrdering::Acquire, guard);\n                    if !child.is_null() {\n                        self.collect_range(child, start, end, result, guard);\n                    }\n                }\n                \n                if k >= start && k < end {\n                    // Internal nodes don't store values in this implementation\n                }\n            }\n            \n            if let Some(last_child) = node.children.last() {\n                let child = last_child.load(AtomicOrdering::Acquire, guard);\n                if !child.is_null() {\n                    self.collect_range(child, start, end, result, guard);\n                }\n            }\n        }\n    }\n\n    pub fn len(&self) -> usize {\n        self.len.load(AtomicOrdering::Relaxed)\n    }\n\n    pub fn is_empty(&self) -> bool {\n        self.len() == 0\n    }\n}\n\nimpl Drop for ConcurrentBTree {\n    fn drop(&mut self) {\n        let guard = &epoch::pin();\n        let root = self.root.load(AtomicOrdering::Acquire, guard);\n        if !root.is_null() {\n            unsafe {\n                guard.defer_destroy(root);\n            }\n        }\n    }\n}",
  "score": 160.0,
  "correct": false,
  "generation": 1,
  "parent_id": "81f75b4e76827f70",
  "island": 0,
  "level_reached": 0,
  "progress": "LockFree",
  "feedback": "## Cascade Results:\n- rustc: PASS (36.8s)\n- miri: FAIL (50.1s) â€” error: \"error: Undefined Behavior: trying to retag from <145480> for SharedReadWrite permission at alloc44603[0x8], but that tag does not exist in the borrow stack for this location\"\n  output: \"\\nrunning 8 tests\\ntest tests::tests::test_concurrent_inserts_no_lost_keys ... \\n   Compiling libc v0.2.180\\n   Compiling cfg-if v1.0.4\\n   Compiling getrandom v0.3.4\\n   Compiling once_cell v1.21.3\\n   Compiling rustversion v1.0.22\\n   Compiling shlex v1.3.0\\n   Compiling rustix v1.1.3\\n   Compiling regex-syntax v0.8.9\\n   Compiling find-msvc-tools v0.1.9\\n   Compiling zerocopy v0.8.39\\n   Compiling autocfg v1.5.0\\n   Compiling tracing-core v0.1.36\\n   Compiling cc v1.2.55\\n   Compiling log v0.4.29\\n   Compiling bitflags v2.10.0\\n   Compiling crossbeam-utils v0.8.21\\n   Compiling pin-project-lite v0.2.16\\n   Compiling lazy_static v1.5.0\\n   Compiling fastrand v2.3.0\\n   Compiling num-traits v0.2.19\\n   Compiling sharded-slab v0.1.7\\n   Compiling thread_local v1.1.9\\n   Compiling fnv v1.0.7\\n   Compiling quick-error v1.2.3\\n   Compiling bit-vec v0.8.0\\n   Compiling tracing v0.1.44\\n   Compiling tracing-log v0.2.0\\n   Compiling smallvec v1.15.1\\n   Compiling nu-ansi-term v0.50.3\\n   Compiling bit-set v0.8.0\\n   Compiling unarray v0.1.4\\n   Compiling scoped-tls v1.0.1\\n   Compiling crossbeam-epoch v0.9.18\\n   Compiling errno v0.3.14\\n   Compiling wait-timeout v0.2.1\\n   Compiling rand_core v0.9.5\\n   Compiling rand_xorshift v0.4.0\\n   Compiling rand v0.9.2\\n   Compiling vf-temp-crate v0.1.0 (/private/var/folders/rc/g8khp7x95kj573cxkyp1swb40000gq/T/vf-cascade-10348333954741596992)\\nwarning: unused import: `std::cmp::Ordering`\\n --> src/lib.rs:2:5\\n  |\\n2 | use std::cmp::Ordering;\\n  |     ^^^^^^^^^^^^^^^^^^\\n  |\\n  = note: `#[warn(unused_imports)]` (part of `#[warn(unused)]`) on by default\\n\\nwarning: field `next` is never read\\n  --> src/lib.rs:12:5\\n   |\\n 8 | struct Node {\\n   |        ---- field in this struct\\n...\\n12 |     next: Atomic<Node>,\\n   |     ^^^^\\n   |\\n   = note: `Node` has a derived impl for the trait `Debug`, but this is intentionally ignored during dead code analysis\\n   = note: `#[warn(dead_code)]` (part of `#[warn(unused)]`) on by default\\n\\nwarning: associated function `new_internal` is never used\\n  --> sr\"\n",
  "model": "opus"
}